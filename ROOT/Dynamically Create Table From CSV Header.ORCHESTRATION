{"job":{"components":{"2204":{"id":2204,"inputCardinality":"ZERO","outputCardinality":"MANY","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":444132438,"x":-832,"y":0,"width":32,"height":32,"inputConnectorIDs":[],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[2208],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Start","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Start 0"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"2205":{"id":2205,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186829,"x":-672,"y":0,"width":32,"height":32,"inputConnectorIDs":[2208],"outputSuccessConnectorIDs":[2207],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Read CSV header row in S3 File"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"###\n# Variables are directly accessible: \n#   print (myvar)\n# Updating a variable:\n#   context.updateVariable('myvar', 'new-value')\n# Grid Variables are accessible via the context:\n#   print (context.getGridVariable('mygridvar'))\n# Updating a grid variable:\n#   context.updateGridVariable('mygridvar', [['list','of'],['lists','!']])\n# A database cursor can be accessed from the context (Jython only):\n#   cursor = context.cursor()\n#   cursor.execute('select count(*) from mytable')\n#   rowcount = cursor.fetchone()[0]\n###\n\nimport boto3\nimport pandas as pd\nimport datetime\nimport re\n\n# GET TIMESTAMP OF SCRIPT RUN FOR METADATA HISTORY\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(timestamp)\n\n# USES NATIVE CREDENTIALS OF METL INSTANCE\ns3 = boto3.client('s3')\n\nBUCKET_NAME = s3_bucket_name\n\ngrid_data = []\n\ns3filename = s3_filename\n#print(s3filename)\n\nstg_clean_table_name = \"stg_\" + re.sub('\\W','_',s3filename).lower()\ncontext.updateVariable('s3_stg_clean_table_name', stg_clean_table_name)\n#print(stg_clean_table_name)\n\n# READ S3 FILE HEADER\ns3file = s3.get_object(Bucket=BUCKET_NAME, Key=s3filename) \ndf_cols = pd.read_csv(s3file.get(\"Body\"), nrows=0).columns.tolist()\n#print(df_cols)\n\n# LOOP THROUGH THE COLUMNS\ncol_no = 1\nfor col in df_cols:\n  grid_row = []\n  grid_row.append(s3filename)\n  grid_row.append(str(col_no))\n  grid_row.append(col)\n  grid_row.append(timestamp)\n  grid_row.append(stg_clean_table_name)\n  grid_row.append(\"VARCHAR\")\n  grid_row.append(\"100000\")\n  grid_row.append(\"No\")\n  grid_row.append(\"No\")\n  grid_row.append(\"\")\n  grid_row.append(\"\")\n  grid_row.append(\"\")\n  col_no += 1\n  grid_data.append(grid_row)\n\n# WRITE COLUMN DEFINITIONS TO GRID\ncontext.updateGridVariable('s3_csvfile_metadata',grid_data)\nprint(context.getGridVariable('s3_csvfile_metadata'))\n\n"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":true},"5":{"slot":5,"name":"User","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Restricted"}}}},"visible":false}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"2206":{"id":2206,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":1611478312,"x":-512,"y":0,"width":32,"height":32,"inputConnectorIDs":[2207],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Create Table Dynamically"}}}},"visible":true},"2":{"slot":2,"name":"Database","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"[Environment Default]"}}}},"visible":true},"3":{"slot":3,"name":"Schema","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"[Environment Default]"}}}},"visible":true},"4":{"slot":4,"name":"New Table Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"${s3_stg_clean_table_name}"}}}},"visible":true},"5":{"slot":5,"name":"Columns","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"GRID","value":"s3_csvfile_metadata"}}},"2":{"slot":2,"values":{"1":{"slot":1,"type":"GRID","value":"column_name"},"2":{"slot":2,"type":"GRID","value":"column_type"},"3":{"slot":3,"type":"GRID","value":"column_size"},"4":{"slot":4,"type":"GRID","value":"column_precision"},"5":{"slot":5,"type":"GRID","value":"column_default_value"},"6":{"slot":6,"type":"GRID","value":"column_not_null"},"7":{"slot":7,"type":"GRID","value":"column_unique"},"8":{"slot":8,"type":"GRID","value":"column_comment"}}}},"visible":true},"6":{"slot":6,"name":"Create/Replace","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Replace"}}}},"visible":true},"7":{"slot":7,"name":"Clustering Keys","elements":{},"visible":true},"8":{"slot":8,"name":"Data Retention Time in Days","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":""}}}},"visible":true},"9":{"slot":9,"name":"Comment","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":""}}}},"visible":true},"11":{"slot":11,"name":"Primary Keys","elements":{},"visible":true},"12":{"slot":12,"name":"Table Type","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Permanent"}}}},"visible":true},"13":{"slot":13,"name":"Default DDL Collation","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":""}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]}},"successConnectors":{"2207":{"id":2207,"sourceID":2205,"targetID":2206}},"failureConnectors":{},"unconditionalConnectors":{"2208":{"id":2208,"sourceID":2204,"targetID":2205}},"trueConnectors":{},"falseConnectors":{},"iterationConnectors":{},"noteConnectors":{},"notes":{"2203":{"id":2203,"x":-1066,"y":-336,"width":763,"height":292,"text":"**PREREQUISITES**\nThe Pandas python module must be installed.\nTo do this you can use the Bash Script component and run the following command\npip-3.6 install --user pandas\n\n**DESCRIPTION**\nTakes an S3 bucket name and file path as input parameters.\nReads the header row of the file to determine table column names and creates a table with these column names.\n\nIdeal for automation of creating staging tables from s3 files when combined with other components e.g. an iterator.  \n\n**Scalar Input Variables**:\n__s3_bucket_name__  Name of S3 Bucket where source file is located\n__s3_filename__  Filename of source file in S3, includes folder path if not at root\n\n**Scalar Output Variables**:\n__s3_stg_table_name__  Name of the staging table created by the job\n\n**Grid Output Variables**:\n__s3_csvfile_metadata__  Metadata taken from header row that was used by job to create the table","colour":"00ce4f"}},"variables":{"s3_bucket_name":{"definition":{"name":"s3_bucket_name","type":"TEXT","scope":"BRANCH","description":"","visibility":"PUBLIC"},"value":"mtln-richardl"},"s3_filename":{"definition":{"name":"s3_filename","type":"TEXT","scope":"BRANCH","description":"","visibility":"PUBLIC"},"value":"USOIL_D1.csv"},"s3_stg_clean_table_name":{"definition":{"name":"s3_stg_clean_table_name","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},"value":"stg_csv_tbl"}},"grids":{"s3_csvfile_metadata":{"definition":{"name":"s3_csvfile_metadata","scope":"TASKBATCH","definitions":[{"name":"filename","type":"TEXT"},{"name":"column_pos","type":"DECIMAL"},{"name":"column_name","type":"TEXT"},{"name":"scan_date","type":"DATETIME"},{"name":"clean_table_name","type":"TEXT"},{"name":"column_type","type":"TEXT"},{"name":"column_size","type":"TEXT"},{"name":"column_not_null","type":"TEXT"},{"name":"column_unique","type":"TEXT"},{"name":"column_precision","type":"TEXT"},{"name":"column_default_value","type":"TEXT"},{"name":"column_comment","type":"TEXT"}],"description":"","visibility":"PUBLIC"},"values":[{"values":["testfile","0","col_default","2021-11-20 00:00:00","","VARCHAR","100","No","No","","",""]}]}}},"info":{"name":"Dynamically Create Table From CSV Header","description":"Unpacked from Shared Job [Create Table From S3 File Header].","type":"ORCHESTRATION","tag":"062ca84f-4e02-483b-b086-d6d1b88ec099"}}